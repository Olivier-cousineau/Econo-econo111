# Walmart Liquidation Scraper

Ce dossier contient le script Python asynchrone utilis√© pour r√©cup√©rer les produits en liquidation publi√©s sur les pages locales de Walmart Canada.

## Installation locale rapide

```bash
python -m venv .venv
source .venv/bin/activate  # PowerShell: .venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt
playwright install --with-deps chromium
```

> üí° Le script repose sur Playwright. L'installation du navigateur Chromium est n√©cessaire lors du premier lancement (voir la commande `playwright install` ci-dessus).

## Lancer une extraction

```bash
python incoming/walmart_scraper.py
```

Quelques options pratiques :

| Option | Description |
| --- | --- |
| `--store laval` | Limite l'extraction √† un magasin (ID, ville ou slug). |
| `--store laval --store montreal` | Peut √™tre r√©p√©t√© pour cumuler plusieurs magasins. |
| `--no-headless` | Affiche Chromium pendant l'ex√©cution (utile pour d√©boguer). |
| `--output-dir ./sorties` | Sauvegarde les JSON des magasins dans un dossier personnalis√©. |
| `--aggregated-path ./sorties/liquidations.json` | D√©finit le fichier d'agr√©gation final. |
| `--max-concurrent-browsers 1` | R√©duit la concurrence si votre machine est limit√©e. |

Le script cr√©e un fichier `liquidations_walmart_qc.json` (agr√©gat global) et un fichier JSON par magasin dans `data/walmart/` (ou dans le dossier fourni via `--output-dir`).

### Variante HTTP (sans navigateur)

Pour un environnement plus contraint (ex.: ex√©cution locale rapide ou proxy HTTP d√©di√©), le script `incoming/walmart_requests_scraper.py` effectue la m√™me extraction √† l'aide de requ√™tes `requests`/`BeautifulSoup`.

```bash
python incoming/walmart_requests_scraper.py --store saint-jerome
```

Les options (`--store`, `--output-dir`, `--aggregated-path`, etc.) sont identiques √† la version Playwright. Ce scraper repose sur la disponibilit√© du JSON `__NEXT_DATA__` dans la page et peut √©chouer si Walmart modifie la structure. En contrepartie, il d√©marre en quelques secondes et n√©cessite moins de ressources.

## Automatisation

Une action GitHub (`.github/workflows/walmart-scraper.yml`) planifie l'ex√©cution chaque jour √† 21h UTC. Pour l'activer :

1. Ajoutez un secret `WALMART_PROXIES` contenant une liste JSON de proxies r√©sidentiels.
2. Mettez √† jour `incoming/walmart_stores.json` (via `incoming/walmart_stores_raw.tsv`).
3. D√©clenchez manuellement le workflow via l'onglet **Actions** si n√©cessaire (`Run workflow`).

Chaque ex√©cution met √† jour les JSON par magasin dans `data/walmart/` et attache un artefact `liquidations_walmart_qc.json` t√©l√©chargeable depuis GitHub Actions.

# Canadian Tire Clearance Scraper

Le script `incoming/canadian_tire_scraper.py` automatise la r√©cup√©ration des produits en liquidation publi√©s par Canadian Tire. Il lit la liste des magasins depuis `data/canadian-tire/stores.json`, g√©n√®re un fichier JSON par magasin dans `data/canadian-tire/` puis consolide l'ensemble dans un agr√©gat global.

```bash
python incoming/canadian_tire_scraper.py --store laval --store saint-jerome
```

Options principales¬†:

| Option | Description |
| --- | --- |
| `--store` | Peut √™tre r√©p√©t√© pour s√©lectionner des magasins pr√©cis (ID, slug, ville). |
| `--language` | Force la langue des pages magasin cibl√©es (`fr` ou `en`). |
| `--output-dir` | Change le dossier de sortie pour les fichiers par magasin. |
| `--aggregated-path` | D√©place le fichier d'agr√©gation (d√©faut¬†: `liquidations_canadian_tire_qc.json`). |
| `--max-retries`, `--timeout`, `--delay` | Ajustent la tol√©rance r√©seau. |

Chaque ex√©cution sauvegarde les aubaines dans `data/canadian-tire/<ville>.json` et regroupe l'ensemble dans `liquidations_canadian_tire_qc.json`.
