#!/usr/bin/env node
// @ts-check
/**
 * Run the Canadian Tire scraper for every store listed in a matrix file
 * and commit the resulting JSON for each city as soon as it is generated.
 *
 * Usage:
 *   node scripts/run_canadiantire_matrix.js [--file data/canadian-tire/branches.json]
 *                                           [--stores 271,649]
 *                                           [--limit 5]
 *                                           [--maxPages 80]
 *                                           [--dry-run]
 */
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { spawnSync } from "child_process";
import minimist from "minimist";
import slugify from "slugify";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const args = minimist(process.argv.slice(2), {
  string: ["file", "stores", "maxPages"],
  boolean: ["dry-run", "dryRun", "continue"],
  alias: { dryRun: "dry-run" },
});

function parseBooleanArg(value, defaultValue = false) {
  if (value === undefined) return defaultValue;
  if (typeof value === "boolean") return value;
  if (typeof value === "number") return value !== 0;
  if (typeof value === "string") {
    const normalized = value.trim().toLowerCase();
    if (["false", "0", "no", "off"].includes(normalized)) return false;
    if (["true", "1", "yes", "on"].includes(normalized)) return true;
  }
  return defaultValue;
}

const storesFile = args.file || path.join("data", "canadian-tire", "branches.json");
if (!fs.existsSync(storesFile)) {
  console.error(`‚ùå Stores file not found: ${storesFile}`);
  process.exit(1);
}

/**
 * @typedef {{ id: string, name?: string, city?: string }} Store
 */
const raw = JSON.parse(fs.readFileSync(storesFile, "utf8"));
let stores = Array.isArray(raw) ? raw : raw?.stores || [];

if (!Array.isArray(stores) || stores.length === 0) {
  console.error(`‚ùå No stores found inside ${storesFile}`);
  process.exit(1);
}

const filterIds = (args.stores || "")
  .split(/[,\s]+/)
  .map((s) => s.trim())
  .filter(Boolean);
if (filterIds.length) {
  const wanted = new Set(filterIds);
  stores = stores.filter((store) => wanted.has(String(store.id)));
  if (!stores.length) {
    console.error(`‚ùå None of the requested stores (${filterIds.join(", ")}) were found.`);
    process.exit(1);
  }
}

const limit = Number(args.limit ?? args.count ?? args.n ?? 0);
if (Number.isFinite(limit) && limit > 0) {
  stores = stores.slice(0, limit);
}

const dryRun = parseBooleanArg(args["dry-run"] ?? args.dryRun, false);
const continueOnError = parseBooleanArg(args.continue ?? args["continue-on-error"], false);

const extraScraperArgs = [];
if (args.maxPages) {
  extraScraperArgs.push("--maxPages", String(args.maxPages));
}
if (parseBooleanArg(args.headful, false)) {
  extraScraperArgs.push("--headful");
}
const passthrough = [
  { key: "include-regular-price", flag: "--include-regular-price" },
  { key: "includeRegularPrice", flag: "--includeRegularPrice" },
  { key: "include-liquidation-price", flag: "--include-liquidation-price" },
  { key: "includeLiquidationPrice", flag: "--includeLiquidationPrice" },
];
for (const { key, flag } of passthrough) {
  if (key in args) {
    extraScraperArgs.push(flag, String(args[key]));
  }
}

console.log(`üì¶ Stores file: ${storesFile}`);
console.log(`üßÆ ${stores.length} store(s) to scrape`);
if (dryRun) console.log("‚ö†Ô∏è Dry run mode: scrapes will be skipped, commits will not be created");

const scraperEntry = path.join(__dirname, "..", "scraper_ct.js");

for (const store of stores) {
  const cityLabel = store.city || store.name || "";
  if (!store.id || !cityLabel) {
    console.warn(`‚ö†Ô∏è Skipping invalid store entry: ${JSON.stringify(store)}`);
    continue;
  }

  console.log(`\n==============================`);
  console.log(`üè¨ Scraping store ${store.id} ‚Äì ${cityLabel}`);

  const scraperArgs = [
    scraperEntry,
    "--store",
    String(store.id),
    "--city",
    cityLabel,
    ...extraScraperArgs,
  ];

  if (dryRun) {
    console.log(`(dry-run) node ${scraperArgs.join(" ")}`);
  } else {
    const scrape = spawnSync("node", scraperArgs, { stdio: "inherit" });
    if (scrape.status !== 0) {
      console.error(`‚ùå Scraper failed for store ${store.id}`);
      if (!continueOnError) {
        process.exit(scrape.status ?? 1);
      }
      continue;
    }
  }

  const slug = slugify(cityLabel, { lower: true, strict: true }) || "default";
  const storePath = path.join("outputs", "canadiantire", `${store.id}-${slug}`);
  const jsonPath = path.join(storePath, "data.json");

  if (!fs.existsSync(jsonPath)) {
    console.warn(`‚ö†Ô∏è No data.json found at ${jsonPath}`);
    continue;
  }

  if (dryRun) {
    console.log(`(dry-run) would commit ${jsonPath}`);
    continue;
  }

  console.log(`üíæ Committing ${jsonPath}`);
  const gitAdd = spawnSync("git", ["add", jsonPath], { stdio: "inherit" });
  if (gitAdd.status !== 0) {
    console.error(`‚ùå git add failed for ${jsonPath}`);
    if (!continueOnError) process.exit(gitAdd.status ?? 1);
    continue;
  }

  let rows = "?";
  try {
    const content = JSON.parse(fs.readFileSync(jsonPath, "utf8"));
    rows = Array.isArray(content) ? String(content.length) : rows;
  } catch {
    rows = "?";
  }

  const commitMsg = `Canadian Tire: ${cityLabel} (${store.id}) ‚Äì ${rows} produits`;
  const gitCommit = spawnSync("git", ["commit", "-m", commitMsg], { stdio: "inherit" });
  if (gitCommit.status !== 0) {
    console.warn(`‚ö†Ô∏è git commit skipped for ${cityLabel} (store ${store.id})`);
    if (!continueOnError && gitCommit.status !== 1) {
      process.exit(gitCommit.status ?? 1);
    }
  }
}

console.log("\n‚úÖ Done");
